# Sequences Organized by Length

This directory contains protein sequences split into 8 bins based on length.
Each bin is optimized for maximum throughput on AMD MI300X with ESM2-3B.

## Directory Structure

```
sequences_by_length/
├── bin1_0-99aa/           # Very short proteins (batch: 256)
├── bin2_100-199aa/        # Short proteins (batch: 256)
├── bin3_200-299aa/        # Short-medium proteins (batch: 256)
├── bin4_300-399aa/        # Medium proteins (batch: 166)
├── bin5_400-499aa/        # Medium-long proteins (batch: 108)
├── bin6_500-999aa/        # Long proteins (batch: 44)
├── bin7_1000-1999aa/      # Very long proteins (batch: 12)
├── bin8_2000plus_aa/      # Ultra-long proteins (batch: 2)
├── batch_config.csv       # Configuration file
└── run_batch_inference.sh # Automated processing script
```

## Batch Processing

Each folder contains sequences of similar length, allowing optimal batch sizes
for ESM2-3B inference on AMD MI300X (192GB).

### Quick Start

```bash
# Run all batches automatically
./run_batch_inference.sh

# Or process individual bins
conda activate amd_protein
python esm2_inference.py \
    --input sequences_by_length/bin6_500-999aa/bin6_500-999aa.fasta \
    --output embeddings_output/bin6_embeddings.pt \
    --batch-size 44 \
    --precision fp16
```

## Optimization Strategy

- **Short sequences (0-299aa)**: Batch size 256 for maximum throughput
- **Medium sequences (300-499aa)**: Batch sizes 108-166 balancing speed and memory
- **Long sequences (500-1999aa)**: Batch sizes 12-44 due to quadratic attention
- **Ultra-long (2000+aa)**: Batch size 2, attention memory dominates

## Performance

Total processing time: ~1.14 hours using FP16 precision
- 80,374 sequences processed
- ESM2-3B model on AMD MI300X
- Optimal batch sizes per length category

Generated by: split_fasta_by_length.py
